{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d64c0434425550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import List, Dict"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Создаем папку для датасетов\n",
    "os.makedirs(\"datasets\", exist_ok=True)"
   ],
   "id": "5f234278e9127ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ====== 1. Загружаем Spider Dataset ======\n",
    "!wget -O datasets/spider_train.json https://raw.githubusercontent.com/taoyds/spider/master/spider/train.json\n",
    "!wget -O datasets/spider_dev.json https://raw.githubusercontent.com/taoyds/spider/master/spider/dev.json\n",
    "!wget -O datasets/spider_tables.json https://raw.githubusercontent.com/taoyds/spider/master/spider/tables.json\n"
   ],
   "id": "93a9f88d469d4d99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_spider_dataset(path: str, tables_path: str) -> List[Dict]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    with open(tables_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        tables = json.load(f)\n",
    "\n",
    "    db_schemas = {table[\"db_id\"]: table[\"tables\"] for table in tables}\n",
    "\n",
    "    processed_data = []\n",
    "    for item in data:\n",
    "        db_id = item[\"db_id\"]\n",
    "        schema_text = \" \".join([\n",
    "            f\"Table: {table}\\nColumns: {', '.join(columns)}\"\n",
    "            for table, columns in zip(db_schemas[db_id], item[\"query_toks\"])\n",
    "        ])\n",
    "\n",
    "        processed_data.append({\n",
    "            \"schema\": schema_text,\n",
    "            \"question\": item[\"question\"],\n",
    "            \"sql_query\": item[\"query\"]\n",
    "        })\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "\n",
    "spider_train = load_spider_dataset(\"datasets/spider_train.json\", \"datasets/spider_tables.json\")\n",
    "spider_dev = load_spider_dataset(\"datasets/spider_dev.json\", \"datasets/spider_tables.json\")"
   ],
   "id": "cb1477e4a3a2e640"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ====== 2. Загружаем WikiSQL ======\n",
    "!wget -O datasets/wikisql_train.jsonl https://raw.githubusercontent.com/salesforce/WikiSQL/master/data/train.jsonl\n",
    "!wget -O datasets/wikisql_dev.jsonl https://raw.githubusercontent.com/salesforce/WikiSQL/master/data/dev.jsonl"
   ],
   "id": "261eef614f7a180"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_wikisql_dataset(path: str) -> List[Dict]:\n",
    "    data = [json.loads(line) for line in open(path, \"r\", encoding=\"utf-8\")]\n",
    "\n",
    "    processed_data = []\n",
    "    for item in data:\n",
    "        schema_text = f\"Table: {item['table_id']}\\nColumns: {', '.join(item['sql']['col_names'])}\"\n",
    "\n",
    "        processed_data.append({\n",
    "            \"schema\": schema_text,\n",
    "            \"question\": item[\"question\"],\n",
    "            \"sql_query\": item[\"sql\"][\"human_readable\"]\n",
    "        })\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "\n",
    "wikisql_train = load_wikisql_dataset(\"datasets/wikisql_train.jsonl\")\n",
    "wikisql_dev = load_wikisql_dataset(\"datasets/wikisql_dev.jsonl\")"
   ],
   "id": "7a290c224f18c371"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ====== 3. Загружаем BIRD Dataset ======\n",
    "!wget -O datasets/bird_train.json https://raw.githubusercontent.com/megagonlabs/BIRD/main/data/train.json\n",
    "!wget -O datasets/bird_dev.json https://raw.githubusercontent.com/megagonlabs/BIRD/main/data/dev.json"
   ],
   "id": "b90801b696fd7f14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_bird_dataset(path: str) -> List[Dict]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    processed_data = []\n",
    "    for item in data:\n",
    "        schema_text = f\"Table: {item['table']}\\nColumns: {', '.join(item['columns'])}\"\n",
    "\n",
    "        processed_data.append({\n",
    "            \"schema\": schema_text,\n",
    "            \"question\": item[\"query_text\"],\n",
    "            \"sql_query\": item[\"sql\"]\n",
    "        })\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "\n",
    "bird_train = load_bird_dataset(\"datasets/bird_train.json\")\n",
    "bird_dev = load_bird_dataset(\"datasets/bird_dev.json\")"
   ],
   "id": "311639d8b31c0ccd"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ====== Сохраняем обработанные данные ======\n",
    "with open(\"datasets/processed_train.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(spider_train + wikisql_train + bird_train, f, indent=4)\n",
    "\n",
    "with open(\"datasets/processed_dev.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(spider_dev + wikisql_dev + bird_dev, f, indent=4)\n",
    "\n",
    "print(\"✅ Датасеты загружены и обработаны!\")\n"
   ],
   "id": "initial_id"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
